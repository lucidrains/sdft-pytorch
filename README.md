## SDFT - Pytorch (wip)

Explorations into the proposed SDFT, [Self-Distillation Enables Continual Learning](https://arxiv.org/abs/2601.19897), from Shenfeld et al. of MIT

## Citations

```bibtex
@misc{shenfeld2026selfdistillationenablescontinuallearning,
    title   = {Self-Distillation Enables Continual Learning}, 
    author  = {Idan Shenfeld and Mehul Damani and Jonas HÃ¼botter and Pulkit Agrawal},
    year    = {2026},
    eprint  = {2601.19897},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    url     = {https://arxiv.org/abs/2601.19897}, 
}
```
